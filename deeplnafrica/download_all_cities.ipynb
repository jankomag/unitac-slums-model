{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_special_characters(string):\n",
    "    string = string.replace(\" \", \"_\")\n",
    "    string = string.replace(\"/\", \"_\")\n",
    "    string = string.replace(\"[\", \"\")\n",
    "    string = string.replace(\"]\", \"\")\n",
    "    string = string.replace(\"(\", \"\")\n",
    "    string = string.replace(\")\", \"\")\n",
    "    string = string.replace(\"&\", \"and\")\n",
    "    string = string.replace(\"'\", \"\")\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from utils.atmosheric_correction import apply_atmospheric_correction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=d47HOpFNntY9quDk6RrmhEjUP3zkp3xCNGzDRxtFpVA&tc=IxbF7OQ9EqqnJ9nZsho7uXB5KgQsm-dCuYwHVW0JPQM&cc=hiUyObEXNPdgVddWwGtUyiXxZ6Fpy9vWddufBoPSW50>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=d47HOpFNntY9quDk6RrmhEjUP3zkp3xCNGzDRxtFpVA&tc=IxbF7OQ9EqqnJ9nZsho7uXB5KgQsm-dCuYwHVW0JPQM&cc=hiUyObEXNPdgVddWwGtUyiXxZ6Fpy9vWddufBoPSW50</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate() # Trigger the authentication flow.\n",
    "ee.Initialize() # Initialize the library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading all images to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRS = 'EPSG:3857'\n",
    "START_DATE = '2023-01-01'\n",
    "END_DATE = '2024-05-24'\n",
    "CLOUD_FILTER = 15\n",
    "CLD_PRB_THRESH = 50\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST = 1\n",
    "BUFFER = 10\n",
    "COLLECTION = 'COPERNICUS/S2_SR_HARMONIZED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s2_cld_col(aoi, start_date, end_date):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection(COLLECTION)\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "    \n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "    \n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    # dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            geometry   city_ascii iso3\n",
      "0  POLYGON ((-83.88976 9.83215, -84.30990 9.83215...      SanJose  CRI\n",
      "1  POLYGON ((-79.50271 8.69856, -79.88534 8.69855...       Panama  PAN\n",
      "2  POLYGON ((-89.05049 13.63916, -89.31264 13.639...  SanSalvador  SLV\n",
      "3  POLYGON ((-90.42054 14.48689, -90.63939 14.486...    Guatemala  GTM\n",
      "4  POLYGON ((-88.19180 17.48046, -88.24077 17.480...   BelizeCity  BLZ\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "\n",
    "# Load the files\n",
    "files = [\n",
    "    '../data/SHP/SanJose_PS.shp',\n",
    "    '../data/SHP/Panama_PS.shp',\n",
    "    '../data/SHP/SanSalvador_PS_lotifi_ilegal.shp',\n",
    "    '../data/SHP/Guatemala_PS.shp',\n",
    "    '../data/SHP/BelizeCity_PS.shp',\n",
    "    '../data/SHP/Belmopan_PS.shp'\n",
    "]\n",
    "\n",
    "# List to hold bounding boxes and city names\n",
    "bounding_boxes = []\n",
    "cities = []\n",
    "\n",
    "# Load each file and calculate bounding box\n",
    "for file in files:\n",
    "    gdf = gpd.read_file(file)\n",
    "    # Calculate bounding box (envelope)\n",
    "    bbox = gdf.geometry.total_bounds\n",
    "    # Create a shapely box from bounding box coordinates\n",
    "    bounding_box_geometry = box(*bbox)\n",
    "    # Append to list\n",
    "    bounding_boxes.append(bounding_box_geometry)\n",
    "    # Extract city name from file path\n",
    "    city = os.path.basename(file).split('_')[0]  # Assuming city name is before the first underscore\n",
    "    cities.append(city)\n",
    "\n",
    "# Create a GeoDataFrame for bounding boxes\n",
    "gdf_bounding_boxes = gpd.GeoDataFrame(geometry=bounding_boxes, crs=gdf.crs)\n",
    "# Add 'city' column\n",
    "gdf_bounding_boxes['city_ascii'] = cities\n",
    "gdf_bounding_boxes['iso3'] = ['CRI', 'PAN', 'SLV', 'GTM', 'BLZ', 'BLZ']\n",
    "\n",
    "# Reproject to a suitable projected CRS (e.g., UTM)\n",
    "gdf_bounding_boxes = gdf_bounding_boxes.to_crs(epsg=32616)  # UTM zone 16N, suitable for Central America\n",
    "\n",
    "# Add 1km buffer\n",
    "gdf_bounding_boxes['geometry'] = gdf_bounding_boxes.geometry.buffer(1000)\n",
    "\n",
    "# Reproject back to original CRS if needed\n",
    "gdf_bounding_boxes = gdf_bounding_boxes.to_crs(gdf.crs)\n",
    "\n",
    "gdf = gdf_bounding_boxes\n",
    "\n",
    "# Print GeoDataFrame info\n",
    "print(gdf_bounding_boxes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started 6/6 tasks.\n"
     ]
    }
   ],
   "source": [
    "# Dynaimc file region\n",
    "# sica_cities = '../data/0/SICA_DO_cities.parquet'\n",
    "# gdf = gpd.read_parquet(sica_cities)\n",
    "\n",
    "num_cities = len(gdf.index)\n",
    "print(\"Number of cities:\", num_cities)\n",
    "\n",
    "tasks = []\n",
    "skipped_cities = []\n",
    "task_number = 1\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    city_poly = row.geometry\n",
    "    city_name = row[\"city_ascii\"]\n",
    "    country_code = row[\"iso3\"]\n",
    "    minx, miny, maxx, maxy = city_poly.bounds\n",
    "    city_bbox = [[[minx, miny],\n",
    "                  [maxx, miny],\n",
    "                  [maxx, maxy],\n",
    "                  [minx, maxy],\n",
    "                  [minx, miny]]]\n",
    "    geometry = ee.Geometry.Polygon(city_bbox)\n",
    "\n",
    "    AOI = geometry\n",
    "    FILENAME = country_code + '_' + replace_special_characters(city_name) + f'_{END_DATE[:4]}'\n",
    "\n",
    "    s2_cld_col = get_s2_cld_col(AOI, START_DATE, END_DATE)\n",
    "    try:\n",
    "        s2_cld_col = s2_cld_col.map(lambda x: x.clip(AOI))\n",
    "        \n",
    "        s2_cld_corr = (s2_cld_col.map(add_cld_shdw_mask)\n",
    "                                 .map(apply_cld_shdw_mask)\n",
    "                      )\n",
    "\n",
    "        if COLLECTION == 'COPERNICUS/S2_HARMONIZED' or COLLECTION == 'COPERNICUS/S2':\n",
    "            s2_sr_median = apply_atmospheric_correction(img_collection=s2_cld_corr, geometry=geometry).median()\n",
    "        else:\n",
    "            s2_sr_median = s2_cld_corr.median()\n",
    "    except:\n",
    "        print(f\"Skipping file {FILENAME}\")\n",
    "        skipped_cities.append(FILENAME)\n",
    "        task_number += 1\n",
    "        continue\n",
    "    \n",
    "    s2_sr_sub = s2_sr_median.select([\"B2\", \"B3\", \"B4\", \"B8\"])\n",
    "\n",
    "    task = ee.batch.Export.image.toDrive(image=s2_sr_sub,\n",
    "                                        description=FILENAME,\n",
    "                                        folder=\"SICA_UNITAC_cities_tifs\",\n",
    "                                        scale=10,\n",
    "                                        region=AOI,\n",
    "                                        fileNamePrefix=FILENAME,\n",
    "                                        crs=CRS,\n",
    "                                        fileFormat='GeoTIFF')\n",
    "    tasks.append(task)\n",
    "    clear_output(wait=True)\n",
    "    display(f\"Starting task {task_number}/{num_cities}\")\n",
    "    task_number += 1\n",
    "    task.start()\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f\"Started {num_cities-len(skipped_cities)}/{num_cities} tasks.\")\n",
    "if len(skipped_cities) > 0:\n",
    "    print(\"Skipped the following cities:\")\n",
    "    for city in skipped_cities:\n",
    "        print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>geometry_index</th>\n",
       "      <th>minx</th>\n",
       "      <th>miny</th>\n",
       "      <th>maxx</th>\n",
       "      <th>maxy</th>\n",
       "      <th>city_name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>0</td>\n",
       "      <td>-84.387738</td>\n",
       "      <td>9.800620</td>\n",
       "      <td>-83.839765</td>\n",
       "      <td>10.132996</td>\n",
       "      <td>SanJose</td>\n",
       "      <td>POLYGON ((-83.83977 9.79177, -84.38774 9.79177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>0_1</td>\n",
       "      <td>-68.752560</td>\n",
       "      <td>18.577160</td>\n",
       "      <td>-68.689678</td>\n",
       "      <td>18.649025</td>\n",
       "      <td>SalvaleonDeHiguey</td>\n",
       "      <td>POLYGON ((-68.68968 18.56864, -68.75256 18.568...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>0_2</td>\n",
       "      <td>-70.297663</td>\n",
       "      <td>19.264371</td>\n",
       "      <td>-70.230289</td>\n",
       "      <td>19.331745</td>\n",
       "      <td>SanFranciscoDeMacoris</td>\n",
       "      <td>POLYGON ((-70.23029 19.25589, -70.29766 19.255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>0_3</td>\n",
       "      <td>-69.340957</td>\n",
       "      <td>18.433430</td>\n",
       "      <td>-69.255617</td>\n",
       "      <td>18.496312</td>\n",
       "      <td>SanPedroDeMacoris</td>\n",
       "      <td>POLYGON ((-69.25562 18.42491, -69.34096 18.424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>0_4</td>\n",
       "      <td>-70.737837</td>\n",
       "      <td>19.758445</td>\n",
       "      <td>-70.634531</td>\n",
       "      <td>19.830310</td>\n",
       "      <td>PuertoPlata</td>\n",
       "      <td>POLYGON ((-70.63453 19.74999, -70.73784 19.749...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              country geometry_index       minx       miny       maxx  \\\n",
       "0          Costa Rica              0 -84.387738   9.800620 -83.839765   \n",
       "1  Dominican Republic            0_1 -68.752560  18.577160 -68.689678   \n",
       "2  Dominican Republic            0_2 -70.297663  19.264371 -70.230289   \n",
       "3  Dominican Republic            0_3 -69.340957  18.433430 -69.255617   \n",
       "4  Dominican Republic            0_4 -70.737837  19.758445 -70.634531   \n",
       "\n",
       "        maxy              city_name  \\\n",
       "0  10.132996                SanJose   \n",
       "1  18.649025      SalvaleonDeHiguey   \n",
       "2  19.331745  SanFranciscoDeMacoris   \n",
       "3  18.496312      SanPedroDeMacoris   \n",
       "4  19.830310            PuertoPlata   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-83.83977 9.79177, -84.38774 9.79177...  \n",
       "1  POLYGON ((-68.68968 18.56864, -68.75256 18.568...  \n",
       "2  POLYGON ((-70.23029 19.25589, -70.29766 19.255...  \n",
       "3  POLYGON ((-69.25562 18.42491, -69.34096 18.424...  \n",
       "4  POLYGON ((-70.63453 19.74999, -70.73784 19.749...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DOWNLOAD FOR SICA URBAN BOUNDARIES ###\n",
    "sica_cities = '../data/1/all_SICA_urban_boundaries.geojson'\n",
    "gdf = gpd.read_file(sica_cities)\n",
    "\n",
    "# Reproject to a suitable projected CRS (e.g., UTM)\n",
    "gdf_bounding_boxes = gdf.to_crs(epsg=3857)\n",
    "gdf_bounding_boxes['geometry'] = gdf_bounding_boxes.geometry.buffer(1000)\n",
    "gdf_bounding_boxes = gdf_bounding_boxes.to_crs(gdf.crs)\n",
    "gdf = gdf_bounding_boxes\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started 28/28 tasks.\n"
     ]
    }
   ],
   "source": [
    "num_cities = len(gdf.index)\n",
    "print(\"Number of cities:\", num_cities)\n",
    "\n",
    "tasks = []\n",
    "skipped_cities = []\n",
    "task_number = 1\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    city_poly = row.geometry\n",
    "    city_name = row[\"city_name\"]\n",
    "    country_code = row[\"country\"]\n",
    "    minx, miny, maxx, maxy = city_poly.bounds\n",
    "    city_bbox = [[[minx, miny],\n",
    "                  [maxx, miny],\n",
    "                  [maxx, maxy],\n",
    "                  [minx, maxy],\n",
    "                  [minx, miny]]]\n",
    "    geometry = ee.Geometry.Polygon(city_bbox)\n",
    "\n",
    "    AOI = geometry\n",
    "    FILENAME = country_code + '_' + replace_special_characters(city_name) + f'_{END_DATE[:4]}'\n",
    "\n",
    "    s2_cld_col = get_s2_cld_col(AOI, START_DATE, END_DATE)\n",
    "    try:\n",
    "        s2_cld_col = s2_cld_col.map(lambda x: x.clip(AOI))\n",
    "        \n",
    "        s2_cld_corr = (s2_cld_col.map(add_cld_shdw_mask)\n",
    "                                 .map(apply_cld_shdw_mask)\n",
    "                      )\n",
    "\n",
    "        if COLLECTION == 'COPERNICUS/S2_HARMONIZED' or COLLECTION == 'COPERNICUS/S2':\n",
    "            s2_sr_median = apply_atmospheric_correction(img_collection=s2_cld_corr, geometry=geometry).median()\n",
    "        else:\n",
    "            s2_sr_median = s2_cld_corr.median()\n",
    "    except:\n",
    "        print(f\"Skipping file {FILENAME}\")\n",
    "        skipped_cities.append(FILENAME)\n",
    "        task_number += 1\n",
    "        continue\n",
    "    \n",
    "    s2_sr_sub = s2_sr_median.select([\"B2\", \"B3\", \"B4\", \"B8\"])\n",
    "\n",
    "    task = ee.batch.Export.image.toDrive(image=s2_sr_sub,\n",
    "                                        description=FILENAME,\n",
    "                                        folder=\"SICA_UNITAC_cities_tifs_urbanBoundaries\",\n",
    "                                        scale=10,\n",
    "                                        region=AOI,\n",
    "                                        fileNamePrefix=FILENAME,\n",
    "                                        crs=CRS,\n",
    "                                        fileFormat='GeoTIFF')\n",
    "    tasks.append(task)\n",
    "    clear_output(wait=True)\n",
    "    display(f\"Starting task {task_number}/{num_cities}\")\n",
    "    task_number += 1\n",
    "    task.start()\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f\"Started {num_cities-len(skipped_cities)}/{num_cities} tasks.\")\n",
    "if len(skipped_cities) > 0:\n",
    "    print(\"Skipped the following cities:\")\n",
    "    for city in skipped_cities:\n",
    "        print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
