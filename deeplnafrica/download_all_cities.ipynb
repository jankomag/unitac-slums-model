{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_special_characters(string):\n",
    "    string = string.replace(\" \", \"_\")\n",
    "    string = string.replace(\"/\", \"_\")\n",
    "    string = string.replace(\"[\", \"\")\n",
    "    string = string.replace(\"]\", \"\")\n",
    "    string = string.replace(\"(\", \"\")\n",
    "    string = string.replace(\")\", \"\")\n",
    "    string = string.replace(\"&\", \"and\")\n",
    "    string = string.replace(\"'\", \"\")\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from utils.atmosheric_correction import apply_atmospheric_correction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=iT52E7Hg_uu5oFPaXPWbNjzOppCA3Ipmwe0Shd5HAlw&tc=raWlEL8qlG3r1kNPjWRjTfdm21qMHn89F05H0aYxgFk&cc=xTYJRVlTrO1NmhbUW9n_DpKnoPFpuuxLvtkv3tc6zsQ>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=iT52E7Hg_uu5oFPaXPWbNjzOppCA3Ipmwe0Shd5HAlw&tc=raWlEL8qlG3r1kNPjWRjTfdm21qMHn89F05H0aYxgFk&cc=xTYJRVlTrO1NmhbUW9n_DpKnoPFpuuxLvtkv3tc6zsQ</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate() # Trigger the authentication flow.\n",
    "ee.Initialize() # Initialize the library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading all images to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRS = 'EPSG:3857'\n",
    "START_DATE = '2023-01-01'\n",
    "END_DATE = '2024-05-24'\n",
    "CLOUD_FILTER = 15\n",
    "CLD_PRB_THRESH = 50\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST = 1\n",
    "BUFFER = 10\n",
    "COLLECTION = 'COPERNICUS/S2_SR_HARMONIZED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s2_cld_col(aoi, start_date, end_date):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection(COLLECTION)\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "    \n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "    \n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    # dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            geometry   city_ascii iso3\n",
      "0  POLYGON ((-83.88976 9.83215, -84.30990 9.83215...      SanJose  CRI\n",
      "1  POLYGON ((-79.50271 8.69856, -79.88534 8.69855...       Panama  PAN\n",
      "2  POLYGON ((-89.05049 13.63916, -89.31264 13.639...  SanSalvador  SLV\n",
      "3  POLYGON ((-90.42054 14.48689, -90.63939 14.486...    Guatemala  GTM\n",
      "4  POLYGON ((-88.19180 17.48046, -88.24077 17.480...   BelizeCity  BLZ\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "\n",
    "# Load the files\n",
    "files = [\n",
    "    '../data/SHP/SanJose_PS.shp',\n",
    "    '../data/SHP/Panama_PS.shp',\n",
    "    '../data/SHP/SanSalvador_PS_lotifi_ilegal.shp',\n",
    "    '../data/SHP/Guatemala_PS.shp',\n",
    "    '../data/SHP/BelizeCity_PS.shp',\n",
    "    '../data/SHP/Belmopan_PS.shp'\n",
    "]\n",
    "\n",
    "# List to hold bounding boxes and city names\n",
    "bounding_boxes = []\n",
    "cities = []\n",
    "\n",
    "# Load each file and calculate bounding box\n",
    "for file in files:\n",
    "    gdf = gpd.read_file(file)\n",
    "    # Calculate bounding box (envelope)\n",
    "    bbox = gdf.geometry.total_bounds\n",
    "    # Create a shapely box from bounding box coordinates\n",
    "    bounding_box_geometry = box(*bbox)\n",
    "    # Append to list\n",
    "    bounding_boxes.append(bounding_box_geometry)\n",
    "    # Extract city name from file path\n",
    "    city = os.path.basename(file).split('_')[0]  # Assuming city name is before the first underscore\n",
    "    cities.append(city)\n",
    "\n",
    "# Create a GeoDataFrame for bounding boxes\n",
    "gdf_bounding_boxes = gpd.GeoDataFrame(geometry=bounding_boxes, crs=gdf.crs)\n",
    "# Add 'city' column\n",
    "gdf_bounding_boxes['city_ascii'] = cities\n",
    "gdf_bounding_boxes['iso3'] = ['CRI', 'PAN', 'SLV', 'GTM', 'BLZ', 'BLZ']\n",
    "\n",
    "# Reproject to a suitable projected CRS (e.g., UTM)\n",
    "gdf_bounding_boxes = gdf_bounding_boxes.to_crs(epsg=32616)  # UTM zone 16N, suitable for Central America\n",
    "\n",
    "# Add 1km buffer\n",
    "gdf_bounding_boxes['geometry'] = gdf_bounding_boxes.geometry.buffer(1000)\n",
    "\n",
    "# Reproject back to original CRS if needed\n",
    "gdf_bounding_boxes = gdf_bounding_boxes.to_crs(gdf.crs)\n",
    "\n",
    "gdf = gdf_bounding_boxes\n",
    "\n",
    "# Print GeoDataFrame info\n",
    "print(gdf_bounding_boxes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started 6/6 tasks.\n"
     ]
    }
   ],
   "source": [
    "# Dynaimc file region\n",
    "# sica_cities = '../data/0/SICA_DO_cities.parquet'\n",
    "# gdf = gpd.read_parquet(sica_cities)\n",
    "\n",
    "num_cities = len(gdf.index)\n",
    "print(\"Number of cities:\", num_cities)\n",
    "\n",
    "tasks = []\n",
    "skipped_cities = []\n",
    "task_number = 1\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    city_poly = row.geometry\n",
    "    city_name = row[\"city_ascii\"]\n",
    "    country_code = row[\"iso3\"]\n",
    "    minx, miny, maxx, maxy = city_poly.bounds\n",
    "    city_bbox = [[[minx, miny],\n",
    "                  [maxx, miny],\n",
    "                  [maxx, maxy],\n",
    "                  [minx, maxy],\n",
    "                  [minx, miny]]]\n",
    "    geometry = ee.Geometry.Polygon(city_bbox)\n",
    "\n",
    "    AOI = geometry\n",
    "    FILENAME = country_code + '_' + replace_special_characters(city_name) + f'_{END_DATE[:4]}'\n",
    "\n",
    "    s2_cld_col = get_s2_cld_col(AOI, START_DATE, END_DATE)\n",
    "    try:\n",
    "        s2_cld_col = s2_cld_col.map(lambda x: x.clip(AOI))\n",
    "        \n",
    "        s2_cld_corr = (s2_cld_col.map(add_cld_shdw_mask)\n",
    "                                 .map(apply_cld_shdw_mask)\n",
    "                      )\n",
    "\n",
    "        if COLLECTION == 'COPERNICUS/S2_HARMONIZED' or COLLECTION == 'COPERNICUS/S2':\n",
    "            s2_sr_median = apply_atmospheric_correction(img_collection=s2_cld_corr, geometry=geometry).median()\n",
    "        else:\n",
    "            s2_sr_median = s2_cld_corr.median()\n",
    "    except:\n",
    "        print(f\"Skipping file {FILENAME}\")\n",
    "        skipped_cities.append(FILENAME)\n",
    "        task_number += 1\n",
    "        continue\n",
    "    \n",
    "    s2_sr_sub = s2_sr_median.select([\"B2\", \"B3\", \"B4\", \"B8\"])\n",
    "\n",
    "    task = ee.batch.Export.image.toDrive(image=s2_sr_sub,\n",
    "                                        description=FILENAME,\n",
    "                                        folder=\"SICA_UNITAC_cities_tifs\",\n",
    "                                        scale=10,\n",
    "                                        region=AOI,\n",
    "                                        fileNamePrefix=FILENAME,\n",
    "                                        crs=CRS,\n",
    "                                        fileFormat='GeoTIFF')\n",
    "    tasks.append(task)\n",
    "    clear_output(wait=True)\n",
    "    display(f\"Starting task {task_number}/{num_cities}\")\n",
    "    task_number += 1\n",
    "    task.start()\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f\"Started {num_cities-len(skipped_cities)}/{num_cities} tasks.\")\n",
    "if len(skipped_cities) > 0:\n",
    "    print(\"Skipped the following cities:\")\n",
    "    for city in skipped_cities:\n",
    "        print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.read_file(\"../data/1/UNITAC_data/SantoDomingo_PS_modified.geojson\")\n",
    "# minx, miny, maxx, maxy = gdf.total_bounds\n",
    "# city_bbox = [[[minx, miny],\n",
    "#                 [maxx, miny],\n",
    "#                 [maxx, maxy],\n",
    "#                 [minx, maxy],\n",
    "#                 [minx, miny]]]\n",
    "# geometry = ee.Geometry.Polygon(city_bbox)\n",
    "# AOI = geometry\n",
    "# FILENAME = 'SantoDomingo_' + f'_{START_DATE, END_DATE[:4]}'\n",
    "\n",
    "# s2_cld_col = get_s2_cld_col(AOI, START_DATE, END_DATE)\n",
    "# try:\n",
    "#     s2_cld_col = s2_cld_col.map(lambda x: x.clip(AOI))\n",
    "    \n",
    "#     s2_cld_corr = (s2_cld_col.map(add_cld_shdw_mask)\n",
    "#                                 .map(apply_cld_shdw_mask))\n",
    "#     s2_sr_median = s2_cld_corr.median()\n",
    "# except:\n",
    "#     print(\"Skipping file\")\n",
    "\n",
    "# s2_cld_col = get_s2_cld_col(AOI, START_DATE, END_DATE)\n",
    "# s2_sr_sub = s2_sr_median.select([\"B2\", \"B3\", \"B4\", \"B8\"])\n",
    "\n",
    "# task = ee.batch.Export.image.toDrive(image=s2_sr_sub,\n",
    "#                                     description=\"unitacSDfile\",\n",
    "#                                     folder=\"UNITAC_pro_tifs\",\n",
    "#                                     scale=10,\n",
    "#                                     region=AOI,\n",
    "#                                     fileNamePrefix=FILENAME,\n",
    "#                                     crs=CRS,\n",
    "#                                     fileFormat='GeoTIFF')\n",
    "# clear_output(wait=True)\n",
    "# display(f\"Starting task SD\")\n",
    "# task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Median cloudless\n",
    "# minx, miny, maxx, maxy = gdf.total_bounds\n",
    "# city_bbox = [[[minx, miny],\n",
    "#               [maxx, miny],\n",
    "#               [maxx, maxy],\n",
    "#               [minx, maxy],\n",
    "#               [minx, miny]]]\n",
    "# geometry = ee.Geometry.Polygon(city_bbox)\n",
    "# AOI = geometry\n",
    "\n",
    "# # Define the date range\n",
    "# START_DATE = '2023-01-01'\n",
    "# END_DATE = '2024-05-24'\n",
    "\n",
    "# # Function to mask clouds using the QA60 band\n",
    "# def maskS2clouds(image):\n",
    "#     qa = image.select('QA60')\n",
    "#     cloudBitMask = 1 << 10\n",
    "#     cirrusBitMask = 1 << 11\n",
    "#     mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "#     return image.updateMask(mask).divide(10000)\n",
    "\n",
    "# # Load Sentinel-2 surface reflectance data\n",
    "# collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "#     .filterDate(START_DATE, END_DATE) \\\n",
    "#     .filterBounds(AOI) \\\n",
    "#     .map(maskS2clouds)\n",
    "\n",
    "# # Compute the median composite to reduce cloud cover\n",
    "# median_image = collection.median().clip(AOI)\n",
    "\n",
    "# # Define export parameters\n",
    "# FILENAME = 'unitacSDfile_median'\n",
    "# CRS = 'EPSG:4326'  # You can change to your preferred coordinate reference system\n",
    "\n",
    "# # Export the image to Google Drive\n",
    "# task = ee.batch.Export.image.toDrive(image=median_image,\n",
    "#                                      description=\"unitacSDfile\",\n",
    "#                                      folder=\"UNITAC_pro_tifs\",\n",
    "#                                      scale=10,\n",
    "#                                      region=AOI,\n",
    "#                                      fileNamePrefix=FILENAME,\n",
    "#                                      crs=CRS,\n",
    "#                                      fileFormat='GeoTIFF')\n",
    "\n",
    "# # Start the task\n",
    "# task.start()\n",
    "\n",
    "# # Print a message\n",
    "# print(\"Starting task SD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
